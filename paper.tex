\documentclass[twocolumn,final]{svjour3}

\newcommand{\thetitle}{Linear Representation of Network Traffic}
\newcommand{\theauthors}{
  Stefan~Karpinski \and
  Elizabeth~M.~Belding \and
  Kevin~C.~Almeroth \and
  John~R.~Gilbert
}

%\usepackage{type1cm}
%\usepackage[pdftex]{graphicx}
\usepackage[labelfont=bf,small]{caption}
\usepackage[font=small,labelfont=bf,position=top,nearskip=0em]{subfig}
\usepackage{cite,amsmath,amssymb,rotating,multirow,bigstrut,url,wrapfig,relsize,paralist,array}
\usepackage[hyperfigures,bookmarks,bookmarksopen,bookmarksnumbered,colorlinks,linkcolor=black,citecolor=black,filecolor=blue,menucolor=black,pagecolor=blue,frenchlinks=true,pdftitle={\thetitle}]{hyperref}

\newcommand{\caps}[1]{{\smaller{#1}}}

\title{\thetitle}
\author{\theauthors}
\institute{
  S.~Karpinski \and
  E.~Belding \and
  K.~Almeroth \and
  J.~Gilbert \\
  Department of Computer Science \\
  University of California, Santa Barbara (USA) \\
  Email: \texttt{\{sgk,ebelding,almeroth,gilbert\}@cs.ucsb.edu}
}

\newcommand{\Section}[1]{\hyperref[sec:#1]{Section~\ref*{sec:#1}}}
\newcommand{\Equation}[1]{\hyperref[eqn:#1]{Equation~\ref*{eqn:#1}}}
\newcommand{\Figure}[1]{\hyperref[fig:#1]{Figure~\ref*{fig:#1}}}
\newcommand{\Table}[1]{\hyperref[tab:#1]{Table~\ref*{tab:#1}}}

\newcommand{\FHC}{Hern\'andez-Campos~\textit{et~al.}}
\newcommand{\class}[1]{\textsc{#1}}
\newcommand{\model}[1]{\textsf{#1}}
\newcommand{\RFC}[1]{\caps{RFC}~{#1}}

\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\N}{\mathcal{N}}
\DeclareMathOperator{\Def}{def}
\DeclareMathOperator{\Val}{val}

\newcommand{\defeq}{\stackrel{\Def}{=}{}}
\newcommand{\eqnote}[1]{\text{\footnotesize{[#1]}}}

\newcommand{\X}{\mathsf{X}}
\newcommand{\M}{\mathsf{M}}
\newcommand{\E}[1]{\left<#1\right>}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\Qt}{Q_{\text{time}}}
\newcommand{\Qb}{Q_{\text{byte}}}
\newcommand{\Qi}{Q_{\text{ival}}}
\newcommand{\Di}{Q^{-1}_{\text{ival}}}
\newcommand{\ones}[1]{\mathbf{1}_{#1}}
\newcommand{\zeros}[1]{\mathbf{0}_{#1}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\mean}[1]{\bar{#1}}
\newcommand{\trans}[1]{{#1}^T}
\newcommand{\inner}[2]{{#1}\cdot{#2}}

\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\absx}[1]{|#1|}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\setx}[1]{\{#1\}}
\newcommand{\parens}[1]{\left(#1\right)}
\newcommand{\parensx}[1]{(#1)}
\newcommand{\seq}[1]{\left<#1\right>}
\newcommand{\seqx}[1]{<#1>}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\floorx}[1]{\lfloor#1\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\ceilx}[1]{\lceil#1\rceil}
\newcommand{\round}[1]{\left[#1\right]}
\newcommand{\roundx}[1]{[#1]}
\newcommand{\fracx}[2]{#1/#2}
\newcommand{\fracp}[2]{\left(\frac{#1}{#2}\right)}
\newcommand{\fracpx}[2]{(#1/#2)}

\renewcommand{\bullet}{\raisebox{2pt}{$\centerdot$}}
%\renewcommand{\labelitemi}{\bullet}
\newcommand{\latin}[1]{\textit{#1}}

\newcommand{\newfootnote}[2]{\newcommand{#1}{\footnote{#2} }}

\graphicspath{{graphs/}}

\begin{document}
\maketitle

\begin{abstract}
We propose a representation of wireless workload patterns as large, sparse matrices and provide a method for stochastically generating experimental workload from a given matrix. The essential property of the algebraic representation is that the summation of vectors naturally yields a faithful description of the aggregate behavior of the corresponding flows. This deceptively simple property allows us to express many common concepts from traffic modeling succinctly in terms of a few linear transformations. The algebraic representation has many benefits: 1)~it makes the meaning of generally understood but vague concepts, such as ``uniform behavior,'' mathematically precise and unambiguous; 2)~it allows us to see clearly, through the lens of linear algebra, the implications of common modeling assumptions; 3)~the implementation of traffic models becomes unprecedentedly simple and orthogonal, requiring only a handful of high-level matrix operations, which can be freely composed; 4)~the vast body of algebraic theory and highly optimized numerical linear software may immediately be applied to traffic modeling. We use the paired differential simulation methodology introduced by the authors in previous work to experimentally demonstrate that the general matrix model accurately reproduces realistic network performance~\cite{Karpinski07:realism,Karpinski07:cbr-failure}. We use the same experimental methodology to explore the implications of various assumptions and simplifications that are commonly made in traffic modeling.
%We demonstrate experimentally that the general matrix model accurately reproduces network performance metrics, using the differential simulation methodology introduced in~\cite{Karpinski07:realism} and applied in~\cite{Karpinski07:cbr-failure} to common uniform traffic models. A range of common modeling approaches are implemented in the general matrix model and evaluated experimentally.
%
%We demonstrate how linear algebra can be effectively used to represent and perform computations with traffic behaviors in wireless networks. Moreover, we map common concepts and techniques from traffic modeling into this new algebraic domain, showing how they can be expressed with mathematical precision and succinctness, while simultaneously being made clearer and more general. We demonstrate experimentally that the general matrix model accurately reproduces network performance metrics, using the differential simulation methodology introduced in~\cite{Karpinski07:realism} and applied in~\cite{Karpinski07:cbr-failure} to discredit the common constant bit-rate model. A range of common modeling approaches are implemented in the general matrix model and evaluated experimentally. We conclude with future directions for modeling research based on the new algebraic framework.
\end{abstract}

\keywords{
  traffic modeling \and
  traffic analysis \and
  workload generation \and
  network simulation \and
  linear algebra \and
  matrix analysis
}

\section{Introduction}\label{sec:intro}

\newfootnote{\flownote}{We use the common definition of a \textit{flow} as a sequence of packets sharing the same  ``5-tuple'': \caps{IP} protocol type, source and destination nodes, and \caps{TCP/UDP} port numbers.}

\newfootnote{\marginalnote}{The term ``marginal'' refers to the margins of actuarial tables formerly used for statistical computations. The rows and columns of the table represent possible values of two properties. Each entry in a table contains a count of the number of events falling into the joint category for that row and column. The margins contain sums of the rows or columns, thus giving the distribution of properties along each dimension \emph{independent} of each other.}

More than twenty years of research in analysis and modeling of network traffic have yielded tremendous advances in our understanding of the complex behaviors that emerge from the interaction of millions of humans and computers on the Internet and in local-area networks (\caps{LAN}s).
Both traffic analysis and realistic workload generation, however, remain active areas of research with many unanswered questions.
One of the major challenges of modeling full-network traffic is the multilevel interdependence of packet, flow\flownote and node behaviors.
Three types of simplifying assumptions are commonly applied in both analysis and generation:
\begin{enumerate}
\item \textbf{Uniform:} that traffic behaviors are uniformly distributed. For example, assuming that  all nodes in a network have equal probability of being the source or destination of each flows.
Another common example is the assumption that all packet sizes and inter-packet intervals are the same; this is commonly known as the ``constant bit-rate'' (\caps{CBR}) model.
\item \textbf{Marginal:} that traffic properties share a single, common \emph{marginal}\marginalnote distribution across the entire network, and individual values are drawn independently and unconditionally from this shared distribution.
For example, assuming that a single distribution of packet sizes describes all flows in a network, as compared to equipping each flow in the network with its own specific distribution.
\item \textbf{Conditional:} that traffic behaves marginally, but only within equivalence classes defined by certain conditions.
The assumption, for example, that all flows emanating from a common source node share the same packet size distribution would be a conditional model, conditioned on source nodes.
\end{enumerate}
We would be arguing against a straw man if we implied that researchers who apply these assumptions actually believe them to be true.
They clearly are not: flows have drastically different packet size distributions; different nodes initiate and receive drastically different numbers of packets and flows.
Simply considering intuitive examples of common behavior illustrate this:
downloading a large file \latin{vs.} typing in an \caps{SSH} session;
BitTorrent users \latin{vs.} occasional email checkers.

If no one actually believes that assumptions of uniformity and marginality accurately describe network behavior, then why are these assumptions so common?
The first reason is simply that these assumptions drastically simplify both traffic analysis and workload generation.
If we ignore the interdependencies that make analysis difficult, the difficulties simply evaporate. 
This immediately begs the question of whether these assumptions are benign.
Does assuming uniformity or marginality of network behavior distort the properties and metrics we are trying to analyze and replicate?
We answer this question definitively in the negative: we cannot stick our heads in the sand and pretend that network behaviors are uniform or marginal without severely distorting crucial network performance metrics.

\newfootnote{\realismnote}{It is realistic in the sense that traffic generated using this model accurately reproduces performance metrics of real traffic.}

The second reason why uniformity and marginality assumptions are so commonly used is that there are no generally accepted alternatives for representing or analyzing traffic.
The difficulty lies in the high-dimensional and stochastic nature of network behaviors.
Suppose, for example, that we assume that packet sizes and inter-packet intervals are drawn independently from some given distribution for each flow.
In the terminology introduced above, this is a flow-conditional packet behavior model.
Prior research has indicated that, given accurate per-flow distributions, this is a sufficiently realistic model of network behavior~\cite{Karpinski07:realism}.\realismnote
In this model, however, each flow must have its own specific, realistic pair of distributions for packet size and inter-packet intervals.
Moreover, the distribution of distributions across the entire network must simultaneously be realistic.
Modeling such ``distributions of distributions'' realistically for entire networks is currently an unsolved problem, which we begin to address here.
% This paper provides the mathematical framework in which to address this problem and demonstrates the effectiveness of this framework by taking the first steps towards fully understanding the complex interdependencies of real network behavior.
% make a major first step towards being able to model the distribution of flow behaviors across an entire network, by providing the framework in which to address this problem mathematically, and by demonstrating that this framework actually allows us to meaningfully analyze non-uniform, non-independent cross-network behavior.

Fundamentally, uniform, marginal and conditional models are applied to reduce the dimensionality of network behavior drastically, making analysis and generation tractable problems.
From this perspective, two questions immediately present themselves:
\begin{enumerate}
\item Can we represent ``unreduced'' network behavior in such a way that analysis and generation are still tractable problems?
\item Is there a better way to reduce dimensionality than assuming independence or uniformity of behaviors?
\end{enumerate}
This paper answers both of these questions.
To address the first question, we propose the concept of a \emph{linear representation} of network traffic.
A linear representation of traffic represents each flow's behavior as a vector such that the following linearity condition is satisfied:
\begin{quote}
The sum of the representations of two flows is a vector that represents the aggregate behavior of the two flows.
\end{quote}
A complete traffic sample is expressed as a matrix of such vectors.
Linear representations express full network behavior, without imposing assumptions of uniformity or marginality, yet allow effective traffic analysis and workload generation.
We present a specific linear representation, called the general matrix model (\caps{GMM}), and demonstrate experimentally that in wireless networks this model generates workload that accurately reproduces the performance characteristics of real wireless network traffic.

We address the second question in two parts.
First, we observe that in linear representations of traffic, uniform, marginal and conditional assumptions are simply assertions about rows and columns of the representation matrix being identical to each other. 
Moreover, real traffic matrices can be transformed into the closest uniform, marginal or conditional approximation through simple matrix multiplications.
Viewed this way, the cost of these assumptions becomes immediately apparent: these transformations discard vast amounts of information from the original trace.
It is this wholesale destruction information that causes uniform and marginal traffic models to drastically distort the performance characteristics of real traffic.

To show how traffic can be modeled less destructively, 
% To demonstrate how linear representation allows drastically improved analysis and modeling of network traffic,
we use non-negative matrix factorization to find an low-dimensional approximation of the packet size and inter-packet behavior matrices.
% As an example of how the linear representation allows drastically improved analysis and modeling of network traffic, we apply non-negative matrix factorization to find an low-dimensional representation of packet size and inter-packet flow behaviors.
% Each flow's behavior can be explained as a linear combination of only twelve ``basic behaviors.'' 
% Although they are found purely algorithmically from packet size and inter-packet interval distributions, these behaviors correspond to intuitive mode of network activity.
This factorization simultaneously extracts a small set of ``basic behaviors'' and explains each flow's observed behavior as a mixture of these basic behaviors.
Although the basic behaviors are found algorithmically, they correspond very well with intuitive network activities such as file transfer, typing via \caps{SSH}, and pinging.

% Via this factorization, each flow's behavior as a linear combination a handful of ``basic behaviors'' such as file transfer, typing via \caps{SSH}, ping traffic and other network activities. 
% These intuitive behavior modes as well as the explanation of flows in terms of them are extracted from trace date purely algorithmically.

% First we observe that in any linear representation of traffic, the assumption of uniformity corresponds the criterion that the coefficients in each dimension be the same. 

% To address the second question, we observe that in the general matrix model, 
% 
% Moreover, we apply state of the art matrix factorization techniques to this representation to explain cross-network flow behaviors as linear mixtures of only twelve basic behaviors.

% To address the second question, 

% The second contribution of this paper is to answer these questions and to propose a mathematical representation of network traffic that preserves the non-uniformity and non-independence of flow behaviors in a network, but makes traffic analysis and workload generation from this representation tractable problems.
% Here we will briefly explain our approach.
% 
% It is already common practice in network modeling to think of flow behaviors as vectors.
% The \caps{IP} protocol number, source and destination \caps{IP} addresses, and \caps{UDP/TCP} source and port numbers that define a packet flow are commonly referred to as a 5-tuple---i.e., a vector in five dimensions.
% Other aspects of a flow's behavior can be represented vectorially as well. We call such a mapping of flows into a vector space a \emph{linear representation} if it satisfies the following simple linearity criterion:
% \begin{quote}
% The sum of the representations of two flows is a vector that represents the aggregate behavior of the two flows.
% \end{quote}
% We show that flows can be represented satisfying this criterion. This immediately allows us to perform useful computations on traffic patterns through simple vector addition and scaling.
% Finally, we argue that the natural generalization of this approach is to represent an entire network's behavior as a large matrix, with each row representing a single flow.
% The matrix representation gives a representation of network behavior that preserves the non-uniformity and non-independence of flow behaviors, but still is highly amenable to analysis using theoretical and numerical linear algebra.
% Moreover, we describe how to generate traffic from arbitrary traffic matrices, and demonstrate experimentally that the specific matrix representation we propose preserves the performance characteristics of real traffic.

\input{trace_vs_uniform}

% TODO: update roadmap paragraph.

The rest of the paper is organized as follows. In \Section{motivation} we discuss motivation and related work. The General Matrix Model is presented in \Section{general-matrix-model}. In Sections~\ref{sec:common-properties}~and~\ref{sec:modeling-concepts} we explore how common network properties and modeling concepts can be expressed in the the \caps{GMM} framework. Our experimental and analytical methodology for evaluating traffic models is presented in \Section{methodology}, while the results of our experiments are explained and analyzed in \Section{results}. The ramifications of these results are discussed in \Section{discussion}. Finally, in \Section{conclusions}, we conclude with a discussion of how this research may be applied to current wireless studies. %, and how it points the way to better traffic models for the future.

\section{Motivation \& Related Work}
\label{sec:related-work}
\label{sec:motivation}

%The history of networking research contains many examples of simplistic models that have proven not only to be inaccurate, but also to drastically skew important characteristics of network behavior. Paxson and Floyd showed that the Poisson packet arrival model, which had been standard for studying wide-area Internet traffic, failed to capture the burstiness and self-similarity of real traffic~\cite{Paxson95}. The equally common but simplistic Random Way-Point~(\caps{RWP}) mobility model was found to exhibit ``density waves'' and gradual slow-down of average node speed~\cite{Royer01,Yoon03:speed-decay}. In the worst cases, overly simplistic models can switch the relative performance of protocols, thereby invalidating the conclusions drawn from performance comparisons using those models.

\newfootnote{\QoSnote}{This is violated by some quality of service (QoS) schemes. However, we can simply add QoS metadata---such as traffic classes or urgency flags---to our models of user behavior and the rest of our arguments remain valid. The network is still disinterested in the exact content of the data being transported; only the QoS metadata is relevant.}

The interaction of network users and application behavior with the lower layers of the networking stack is characterized by where, when, how much, and to whom data is transmitted. The joint pattern of traffic generation and mobility through time and space completely determines the effect of wireless usage on the lower levels of the network. This is due to the data-agnostic nature of the protocol stack: by design, \caps{IP} networks treat all data in the same manner~\cite{Clark88}.\QoSnote The credibility of conclusions derived from simulation or experimental deployment depends crucially on our confidence that the models used to generate traffic in experiments are sufficiently realistic. \Figure{trace-vs-uniform} demonstrates how drastically different network traffic appears when assumptions of uniform behavior at various levels are imposed. Assumptions of independence are not as visually dramatic, but we will demonstrate that they distort the performance characteristics of networks almost as much---or more---than uniform models.

Paxson and Floyd observed~\cite{Paxson95} that the interplay between endpoint behavior and the network conditions is inherently \textit{closed-loop} in the sense that it is potentially affected by complex feedback. Traffic models typically attempt to preserve the closed-loop behavior of network traffic~\cite{Avallone04,Hernandez06:dissertation}. This presents a fundamental difficulty, however, in that it presumes that we know the intent of endpoints: what \textit{would} they have done under different conditions? While we can speculate about what an individual node might hypothetically do, we currently hardly understand the impact of the full-network traffic pattern upon performance metrics at all---even without trying to account for hypothetical reactions to alternate situations. A fuller understanding of total network behavior must be reached before we can sensibly tackle the complexities of multi-level behavioral feedback. Accordingly, in this paper we attempt to provide a first-order approximation of complete network behavior by studying the response of performance metrics to \textit{open-loop} traffic models without multi-level feedback. It is important to realize that while this does not provide a final picture, we currently lack even a first-order understanding of the effect of different workloads on performance. This first-order understanding is an essential initial step.

% There have been many studies of large wireless network deployments~\cite{Tang99,Balachandran02,Balazinska03,Kotz02,Henderson04,Schwab04,Chinchilla04,Jardosh05:ewind}. These analyses have described a wide variety of aspects of wireless network behavior, and provide much insight into the workings of real, deployed wireless networks. These studies present a broad analysis of general system features and trends of specific corporate wireless local-area networks (\caps{WLAN}s)~\cite{Tang99,Balazinska03}, university campus \caps{WLAN}s~\cite{Tang00,Kotz02,Chinchilla04,Schwab04,Henderson04,Tuduce05}, and temporary \caps{WLAN}s at conference venues~\cite{Balachandran02,Jardosh05:ewind}. They also provide a large body of raw data for subsequent analysis and modeling research. Our work provides the methodology for turning this rich foundation of field data into usable, realistic models of workload for a wide variety of networking situations.
% 
% The choice of mobility models for mobile wireless simulations can have a drastic impact on important performance metrics~\cite{Camp02,Yoon03:speed-decay,Yoon03:sound-models,Jardosh03,Zheng04}. Moreover, commonly used but simplistic mobility models, such as \caps{RWP}, exhibit characteristics, including density waves and speed decay, that are categorically dissimilar from any known real-world behavior~\cite{Royer01,Yoon03:speed-decay,Yoon03:sound-models}. In response to this evidence, more realistic mobility models have been proposed~\cite{Jardosh03,Tuduce05,Jardosh05:voronoi}. While much of this work focuses on making models that are simply more intuitively appealing~\cite{Jardosh03,Jardosh05:voronoi}, some work has begun to capitalize on this newly created wealth of wireless field data by deriving models from observed usage behavior, rather than intuition alone~\cite{Balazinska03,Tuduce05}.
%The analysis of Balazinska \textit{et al.}~\cite{Balazinska03} introduces the notions of the prevalence and persistence of an \caps{AP} with respect to mobile nodes.\footnote{These concepts are adapted from Paxson's work on Internet routing behavior: ``\textit{prevalence} meaning the overall likelihood that a particular route is encountered, and \textit{persistence}, the likelihood that a route remains unchanged over a long period of time''~\cite{Paxson96}.} Tuduce \textit{et al.}~\cite{Tuduce05} have based their mobility model on the persistence and prevalence characteristics of real trace data, which makes their work particularly relevant to our definition of sufficient realism. They do not, however, determine the impact of prevalence and persistence characteristics on performance metrics.

% In this paper, instead of mobility, we examine an even more fundamental aspect of user behavior in wireless networks: the pattern of traffic generated by users and applications. This aspect of behavior is more fundamental because it applies to all types of wireless networks, not just mobile and ad~hoc networks. Moreover, the effect of traffic patterns applies not only to simulations, but also to experimental deployments, which have become the gold standard for wireless protocol evaluation.  Experimental deployments sidestep the problem of accurately modeling the lower layers of the network. Unless traffic and mobility are modeled realistically, however, the experimental results will still be unreliable.

There is a large and diverse body of work on traffic analysis, modeling, and generation~\cite{Paxson95,Paxson96,Sommers04,Avallone04,Hernandez06:dissertation}. We are only able to discuss a small, but hopefully representative sampling of this work. Almost all of the traffic generation work has focused on wide-area Internet backbone traffic.
%Because of the comparatively unlimited capacity of wired networks, traffic workload generally does not offer interesting technical challenges at the edge of the network.
The two most prominent traffic generation frameworks are Harpoon and \caps{D-ITG}. Harpoon~\cite{Sommers04} uses a traffic trace for self-training, and can subsequently generate synthetic traffic with certain statistical properties based on the original trace. The properties reproduced are the empirical distributions of the following: ``file size, inter-connection time, source and destination IP ranges, number of active sessions.'' There is no criterion proposed to determine whether these properties characterize the original traffic adequately---we can only hope that this approximation is good enough. For many purposes, it likely is sufficient; in particular, it is probably appropriate for the intended use in generating traffic for Internet backbone simulations. Wireless networks, however, are particularly sensitive to workload conditions, and sampling from a limited set of empirical distributions does not suffice to reproduce realistic network-wide traffic.

\caps{D-ITG}~\cite{Avallone04} generates flows using an independent sampling model for packet sizes and inter-packet intervals. The framework contains pre-made models for several common types of Internet traffic. The focus of this project, however, is on providing the infrastructure to generate very large volumes of synthetic Internet-like backbone traffic. No analysis is provided for determining the realism of traffic mixes, or for choosing flow endpoints realistically. In wireless networks, these factors are of crucial importance to performance, and cannot be overlooked. Both Harpoon and \caps{D-ITG} provide excellent traffic generation platforms, but do not provide a systematic framework for understanding or reproducing realistic whole-network workload in the wireless setting.

%This work extends that published in~\cite{Karpinski07:realism}~and~\cite{Karpinski07:cbr-failure}, using the same methodology for defining and quantifying the realism of synthetic traffic models. The Traffic Object Model builds on the combinatorial approach taken in~\cite{Karpinski07:cbr-failure}, while providing an flexible and general object-oriented framework for constructing generative traffic models. The traffic models evaluated here overlap and augment those evaluated in both prior works; comparison with the models proposed in {\FHC} is entirely new. The Qualnet simulation methodology has been enhanced by the implementation of full-duplex, client-server, trace-driven raw \caps{IP}, \caps{TCP}, and \caps{UDP} flows. We have also implemented performance metric aggregation based on the \caps{IETF} framework for \caps{IP} performance metrics~\cite{rfc:ip-metrics,rfc:jitter}.

% TODO: add in the Hernandez-Cortes' dissertation.
% TODO: concluding remarks about what's missing from traffic work in general.
%   + there's no central goal or theme---because realism is ill-defined and subjective
%   + there are no rigorous tests for whether realism is achieved since it's ill-defined
%   + in wireless, where the impact is greater, there's been virtually no research of impact
% TODO: cite a bunch of papers that use the CBR traffic model.

%\section{Algebraic Representations \\of Network Behavior}
\section{The General Matrix Model}
\label{sec:general-matrix-model}
\label{sec:representations}

%The traffic workload pattern in a network is the collection of actions taken by hosts, on behalf of users and applications, that affect the behavior of the network itself. By design, Internet Protocol (\caps{IP}) networks treat all data in the same manner~\cite{Clark88}. Therefore, the actual information transmitted is irrelevant, only the manner of transmission matters. Although networks are packet-switched, packets are logically organized into sequences of packets sharing the same \caps{IP} protocol, source and destination \caps{IP} address, and source and destination  \caps{TCP} or \caps{UDP} port numbers. Such a sequence of packets is called a \textit{flow}. Although there are a vast multitude different application types which use \caps{IP}, there are two fundamentally different behaviors of flows which we distinguish here: \caps{TCP}, which delivers data reliably through feedback and retransmissions; and \caps{UDP}, which delivers data only on a best-effort basis. While it is possible to implement reliable transmission similar to \caps{TCP} over \caps{UDP}, it is uncommon, so we make the generalization that network events, such as packet drops, do not significantly feedback to the behavior of upper layers. With \caps{TCP}, on the other hand, network events are known to affect the transport layer

% TODO: talk about other vector-space representation: perfect representation, markov models, ... others?

The traffic workload pattern in a network is a collection of \caps{IP} packets between hosts in the network sent at certain times. It is standard in network analysis, however, to aggregate sequences of packets sharing the same \caps{IP} protocol, source and destination nodes, and source and destination \caps{TCP} or \caps{UDP} port numbers. Such a sequence of packets is called a \textit{flow}. The traffic pattern of an entire network is simply the collected behaviors of all flows occurring in the network. The behavior of a flow as it affects the network is characterized by the following properties: its \caps{IP} protocol type (\caps{TCP}, \caps{UDP}, \caps{ICMP}, etc.); its source and destination nodes; its start time; and the specific sizes of and intervals between its constituent packets. We propose to represent the behavior of each flow in terms of seven vectors, which suffice to describe all of the above properties in enough detail to stochastically generate realistic traffic. The aggregate behavior of all the flows in a workload pattern are then represented as matrices, the rows of which are the behavior vectors of the flows.

When mapping flow behaviors into a vector space, it is important that the mapping of behaviors into the vector spaces in question respect the vector space operations: addition of vectors and scalar multiplication. This requirement is best clarified with a simplified example. Suppose that the behavior of a flow is represented by the number of packets, $p$, the total bytes transmitted, $b$, and its total duration, $d$. Despite its simplicity, this representation is adequate to reproduce constant bit-rate (\caps{CBR}), time-randomized flow behavior. The triplet of representative values can be naturally embedded into Euclidean space: $\vec{x}=\seq{p,b,d}\in\R^3$. If we have two flows with behavior vectors $\vec{x}_1$ and $\vec{x}_2$, then their sum as vectors, $x_1+x_2=\seq{p_1+p_2,b_1+b_2,d_1+d_2}$, provides an appropriate description of the aggregate behavior of the two flows together. Similarly, their average, i.e. $\frac{1}{2}(\vec{x}_1+\vec{x}_2)$, has the average number of packets, bytes, and duration, which is precisely what the ``average behavior'' of the two flows should intuitively be.

%The behavior of a flow may be mapped into a vector space such that the two operations, namely vector addition and scalar multiplication, naturally correspond with the aggregation of behaviors. This requirement is best clarified with an intentionally simplistic example. Suppose that the behavior of a flow is represented by the number of packets, $p$, the total bytes transmitted, $b$, and the total duration, $d$. This triplet can be naturally embedded into Euclidean space: $\vec{x}=(p,b,d)\in\R^3$. If we have two flows with behavior vectors $\vec{x}_1$ and $\vec{x}_2$, then their ``sum'' behavior, $\vec{x}_1+\vec{x}_2$ has $p_1+p_2$ packets, $b_1+b_2$ bytes, $d_1+d_2$ duration. Their average, i.e. $\frac{1}{2}(\vec{x}_1+\vec{x}_2)$, has the average number of packets, bytes, and duration, which is precisely what the ``average behavior'' of the two flows should intuitively be.

%While this may seem trivial, note that the representation must be chosen carefully. Suppose instead, for example, we represented each flow's behavior by its packet count, $p$, average packet size, $b/p$, and average inter-packet interval, $d/(p-1)$. In this representation, the average of two behaviors has the \textit{average} average packet size, and the \textit{average} average inter-packet interval. Therein lies the rub: this is the case no matter how many packets are in each flow; if a flow with thousands of 1500-byte packets is averaged with a single-packet, one-byte flow, the average behavior has... Instead, we should more naturally weight the averages by the number of packets in each constituent. This is precisely what the packets-bytes-duration representation accomplishes.

The {packets-bytes-duration} representation is clearly overly simplistic and very incomplete. It captures nothing about variability of packet sizes, nor about the ``burstiness'' of packet transmissions; it leaves start time and flow size unspecified; it says nothing about the source or destination of the flow. At the opposite extreme, it is possible to embed the exact start time of each flow, and the exact size and transmission times of its packets, etc. into a vector space. The difficulty comes in doing so in a manner that makes the summation of vectors correspond naturally and meaningfully to the aggregate behavior of flows. We take a highly detailed but intermediate approach, suggested by the results of~\cite{Karpinski07:realism}: to reproduce network performance accurately, it suffices to know, for each flow, the flow type, source node, destination node, start time, flow size, and empirical distributions of packet sizes and inter-packet intervals. If there are $f$ flows in the entire workload pattern, then the collective behavior can be described with six matrices; the rows of each matrix are the behavior vectors of the flows, indexed in some chosen order. We use the following notation for the behavior matrices and their constituent vectors:\vspace{-0.25em}
\begin{tabbing}
\hspace{1em}\=\bullet\hspace{0.5em}\=\hspace{9.75em}\=
$\mat{D}\:$\=$=\parensx{\vec{d}_i}\:$\=$=\parensx{d_{ij}}\:$\=\kill
\>\bullet\> type: \>$\mat{T}$\>$=\parensx{\vec{t}_i}$\>$=\parensx{t_{ij}}$\>$\in\R^{f \times 255}$,\\
\>\bullet\> sources: \>$\mat{S}$\>$=\parensx{\vec{s}_i}$\>$=\parensx{s_{ij}}$\>$\in\R^{f \times n}$,\\
\>\bullet\> destinations: \>$\mat{D}$\>$=\parensx{\vec{d}_i}$\>$=\parensx{d_{ij}}$\>$\in\R^{f \times n}$,\\
\>\bullet\> start times: \>$\mat{A}$\>$=\parensx{\vec{a}_i}$\>$=\parensx{a_{ij}}$\>$\in\R^{f \times d_t}$,\\
\>\bullet\> sizes in bytes: \>$\mat{B}$\>$=\parensx{\vec{b}_i}$\>$=\parensx{b_{ij}}$\>$\in\R^{f \times d_b}$,\\
\>\bullet\> packet sizes: \>$\mat{Z}$\>$=\parensx{\vec{z}_i}$\>$=\parensx{z_{ij}}$\>$\in\R^{f \times d_z}$,\\
\>\bullet\> inter-packet intervals: \>$\mat{V}$\>$=\parensx{\vec{v}_i}$\>$=\parensx{v_{ij}}$\>$\in\R^{f \times d_v}$.
\end{tabbing}
The total behavior is the horizontal concatenation of these component matrices:
\begin{align}
\mat{F} = \seq{\mat{T},\mat{S},\mat{D},\mat{A},\mat{B},\mat{Z},\mat{V}} \in \R^{f \times \Sigma},
\end{align}
where $\Sigma=255+2n+d_t+d_b+d_z+d_v$. Many common traffic models can be expressed succinctly and precisely in terms of transformations or conditions on this behavior matrix and its constituents. In the following sections, we explain in detail how each flow's behavior is represented in these matrices. Finally, we describe how a model instance stochastically generates network traffic.

\subsection{Flow Type}

The type of a flow is its \caps{IP} protocol number. This ranges in possible values from 1 to 255 (0 is reserved for \caps{IPv6}). We represent the flow type as an indicator vector: a 255-dimensional vector consisting of all zeros except for the index which is the flow type. So a \caps{TCP} flow, having protocol type 6, would have the type vector $\vec{t}=\seq{0,0,0,0,0,1,0,\dots,0}$. This representation may immediately strike one as unnecessarily expansive and inefficient since a single byte suffices to represent the protocol type. The necessity of this representation arises when we represent aggregations of flows as sums of vectors. The sum of protocol numbers is meaningless: two \caps{TCP} flows plus five \caps{ICMP} flows does not equal a single \caps{UDP} flow, despite the fact that $2\cdot6+5\cdot1=17$. The summation of the corresponding indicator vectors, however, is $\seq{5,0,0,0,0,2,0,\dots}$. This vector is a histogram indicating the frequency with which each protocol type occurred in the collection of flows over which the sum was taken.

\subsection{Source \& Destination Nodes}

Let $n$ be the number of nodes in the traffic collection to be modeled. We let $s_{ij}=1$ if the $j$th node is the source of the $i$th flow, and zero otherwise; similarly, $d_{ik}=1$ if the destination of the $i$th flow is the $k$th node. This sparse matrix may again seem to be an overly expansive representation, given that start and end nodes can be represented simply as indices from $\set{1,\dots,n}$. The sum of a set of source vectors, $\set{\vec{s}_i}$, however, is an $n$-dimensional histogram indicating how often each source node occurs in the collection.

\subsection{Start Time}

We represent start time of each flow using an indicator vector. Unlike node indices, however, time is continuous, so we must first map times onto a range of time indices $\set{1,\dots,d_t}$. We transform the range $[0,t_{\max}]$ of possible start times using a simple quantization function:
\begin{align}
\label{eqn:time-quantization}
\Qt(t) &= \max\set{1,\ceil{d_t\fracpx{t}{t_{\max}}}}.
\end{align}
%Suppose the $i$th flow has a quantized start index of $j$ and a end index of $k$. Then $b_{ij'}=\delta{jj'}$ and $e_{ik'}=\delta_{kk'}$.
Let $k$ be the quantized start index of a flow. Then the start vectors for the flow is $\vec{a}=\vec{e}_k$ (the $k$th standard basis vector, having 1 at index $k$ and zeros elsewhere). The advantage of this representation becomes clear when we aggregate flows: the sum of start vectors over a collection of flows is a $d_t$-dimensional histogram indicating the frequency of start times occurring in each quantization bin. In practice, we use $d_t=1500$.

\subsection{Flow Size}

We represent flow size with another indicator vector. Although the set of possible flow sizes is discrete, for practical reasons we map the very large range of possible flow sizes down to a much smaller range of indices (some flows in our trace have 109\caps{MB} of data in a single ten-minute period, which would give an indicator vector of over 100 million entries). We use the following function to convert flow sizes to indexes:
\begin{align*}
%\label{eqn:byte-quantization}
\Qb(b) &= \max\set{1,\ceil{d_b\fracp{b-1}{b_{\max}-1}^\beta}}.
\end{align*}
Here $b_{\max}$ is the maximum input flow size. The parameter $\beta$ is a non-linear scaling factor exponent that allows the quantization to smoothly shift from byte-sized resolution at the low end of the possible range of flow sizes to the a resolution of megabytes at the high end of the spectrum. In our example data, $b_{\max}\approx109\text{\caps{MB}}$ as we previously mentioned. We use a representation dimensionality of $d_b=1500$, to match our other quantized vectors, and $\beta=\fracx{1}{2.7}$ because it yields the desired dynamic range response of the possible flow sizes.

\subsection{Packet Sizes \& Inter-Packet Intervals}

The packet size behavior of a flow is represented by a histogram vector, $\vec{z}$, of packet sizes. Explicitly,  $z_{ij}$ is the number of packets in the $i$th flow with $j$ bytes of payload data. The dimension, $d_z$, is the largest possible packet size, which in practice is the maximum transfer unit of the wireless medium, typically 1500 bytes. The representation of inter-packet intervals as a vector, $\vec{v}$, is similar, but the domain of possible intervals is a continuum, so we must map this range onto the discrete index values $\left\{1,\dots,d_v\right\}$. We use similar non-linear quantization function as before:
\begin{align}
\label{eqn:interval-quantization}
\Qi(v) &= \max\set{1,\ceil{d_v\fracp{v-v_{\min}}{v_{\max}-v_{\min}}^\gamma}}.
\end{align}
The element $v_{ij}$ is the number of intervals, $v$, for the $i$th flow such that $\Qi(v)=i$.
The parameter values defining $\Qi$ must be chosen by the experimenter. In our case, the time measurements had microsecond precision, so $v_{\min}=10^{-6}$. The length of each simulated scenario is ten minutes, so the upper limit on intervals is $v_{\max}=600$. The number of dimensions was chosen to match the dimensions for packet size: $d_v=1500$. Finally, the parameter $\gamma\in(0,1)$ allows us to fine-tune how the resolution scales with interval size; we have chosen $\gamma=\frac{1}{3}$ because this choice provides resolution that scales smoothly from the microseconds for small intervals to seconds for large intervals.

\subsection{Traffic Generation}
\label{sec:traffic-generation}

Given an instance of the general matrix model, how do we produce an actual workload from it? Each row of the model is used to randomly generate the behavior of a single flow. The type, source, and destination nodes of the flow are randomly chosen, using histogram vectors $\vec{t}$, $\vec{s}$, and $\vec{d}$ as the proportional probabilities of each type or node being chosen.\footnote{Since a flow must have distinct source and destination nodes, the sampling of endpoints must be done jointly, avoiding the collisions. The simplest technique is the rejection method: if the same node is chosen for both source and destination, reject that pair and begin the selection process again.}
Next we use the flow size vector, $\vec{b}$ to randomly sample the number of bytes in the flow. The packet size and inter-packet interval vectors, $\vec{z}$ and $\vec{v}$, allow us to compute the expected average packet size and inter-packet intervals for the flow (see~\Section{flow-totals}), call them $\mean{z}$ and $\mean{v}$. From these, together with the flow size in bytes, we estimate the expected duration of the flow: $\mean{d} = \fracx{b\mean{v}}{\mean{z}}$. We finally choose a start time for the flow, using $\vec{a}$ as a vector of relative probabilities for each bin of start times, but ensuring that the start time plus the expected duration, $\mean{d}$, does not exceed the maximum simulation time for the workflow. From the range of possible values mapping to the chosen start bin, we choose a random time uniformly.

Having determined the overall parameters of the flow, we generate the actual packets of the flow. The first packet is sent at the chosen start time; the size of each packet is sampled from the histogram of packet sizes, $\vec{z}$; the interval until the next packet is determined from the interval vector, $\vec{v}$. Specifically, an interval index, $k$, is chosen with probability proportional to $\vec{v}(k)$; a second value, $u$, is chosen uniformly from $(0,1]$; the pair $\seq{k,u}$ is transformed back into a continuous time value using the ``dequantization'' function:
\begin{align}
\label{eqn:interval-dequantization}
\Di(k,u)=v_{\min}+(v_{\max}-v_{\min})\left(\frac{k-u}{d_v}\right)^{\frac{1}{\gamma}}.
\end{align}
The packet stream ends when the number of bytes allocated to the flow have been emitted. %The last packet is only the size of the remaining number of bytes.

\section{Expression of Common Properties}
\label{sec:common-properties}

Having defined our representation of network behavior, we turn to deriving useful expressions for commonly used network properties in terms of these algebraic building blocks.

\subsection{Communication Topology}
\label{sec:communication-topology}

The number of flows between each pair of nodes in the network is expressed by the matrix product $\trans{\mat{SD}}\in\R^{n \times n}$ ($\trans{\,\cdot\,}$~denotes transpose). That is $(\trans{\mat{SD}})_{ij}$ is the number of flows from node $i$ to node $j$. The total number of source flows for each node is given by the vector $\trans{\mat{S}}\ones{f}$, and the total number of destination flows is given by $\trans{\mat{D}}\ones{f}$. ($\ones{f}$ is the $f$-dimensional column vector consisting of all ones.)

\subsection{Expected Average Packet Size \& Intervals}
\label{sec:flow-totals}

From the matrices $\mat{Z}$ and $\mat{V}$, we can compute the expected average packet size, $\mean{z}$, and average inter-packet interval, $\mean{v}$, for each flow. The computations require knowing the values that each matrix column represents. The computed duration is only approximate because information is irrecoverably lost in the quantization process (see \Equation{interval-quantization}). The vectors of representative values for $\mat{Z}$ and $\mat{V}$ are:
\begin{align}
\vec{\sigma}&=\seq{1,2,3,\dots,d_z},\\
\vec{\tau}&=\seq{\Di\left(k,\fracx{1}{2}\right)}_{k=1}^{d_v}.
\end{align}
Using these representative values, the expected average packet size and expected average inter-packet interval size for a flow may be computed as
\begin{align}
  \mean{z}&=\frac{\inner{\vec{z}}{\vec{\sigma}}}{\inner{\vec{z}}{\ones{}}}, &
  \mean{v}&=\frac{\inner{\vec{v}}{\vec{\tau}}}{\inner{\vec{v}}{\ones{}}},
\end{align}
respectively, where $\inner{\vec{x}}{\vec{y}}$ denotes the standard inner product of vectors.

\section{Expression of Common Modeling Concepts}
\label{sec:modeling-concepts}

The simplifying assumptions made by most traffic models can be classified into three categories. We use the terms \textit{uniformity}, \textit{marginality}, and \textit{regularity} to describe these classes of assumptions. They are all assumptions about the ``sameness'' of aspects of network behaviors; they differ, however, in whether the make stipulations about uniformity within each flow, across all flows, or within groups of flows. In the following sections, we explore how various modeling concepts can be expressed in the framework of the General Matrix Model. Models are expressed as transformations that will convert arbitrary traffic matrix instances into similar ones that satisfy the model's assumptions. These transformations will later allow us to evaluate the effect of each model's simplifications on the realism of generated workloads.

\subsection{Uniform Behavior}

The concept of uniformity, as used here, entails that certain properties of each flow are assumed to be statistically or deterministically uniform. Examples include: assuming that each flow's packets have the same size and inter-packet interval (i.e. the \caps{CBR} flow model); assuming that each node is equally likely to be the source of a given flow; assuming that all start times for a flow are equally likely.

Since uniform behaviors entail homogeneity of properties with respect to each flow individually, a trace matrix can be transformed to a matrix satisfying the model's assumptions via right matrix multiplication. Right multiplication mixes the elements within each row, and if the mixing weights are uniform, the result is uniform behavior. For example, to make the roles of the nodes with respect to each flow statistically identical, we transform $\mat{S}$ and $\mat{D}$:
\begin{align*}
\mat{S}' &= \mat{S}\ones{n \times n}/n, & \mat{D}' &= \mat{D}\ones{n \times n}/n.
\end{align*}
This makes all the values in each flow's row identically the average of the original $n$ values. As another example, the constant bit-rate (\caps{CBR}) flow model, in its strictest sense, is an intra-flow model, which stipulates that all the packets in each flow behave identically, having identical sizes and intervals; thus each flow's bit-rate is constant, as the name implies. The strict \caps{CBR} model can be easily expressed with the packets-bytes-duration (\caps{PBD}) model used as an example in \Section{representations}. The pair of matrices $\seq{\mat{Z},\mat{V}}$ is transformed to \caps{PBD} form using the vectors defined in \Section{flow-totals}: $\seq{\mat{Z},\mat{V}}\Gamma\in\R^{f \times 3}$, where
\begin{align}
\Gamma=\begin{pmatrix}
\ones{} & \vec{\sigma} & \zeros{} \\
\zeros{} & \zeros{} & \vec{\tau}
\end{pmatrix} \in \R^{(d_v+d_z)\times{3}}.
\end{align}
\Figure{trace-vs-uniform} graphically depicts examples of uniform behaviors as compared to realistic behaviors from traces.
%By replacing $\mat{S}'$ with $\mat{S}$, this can also be viewed as a set of linear constraints on the matrix $\mat{S}$, providing a proscriptive definition 

%We use the term \textit{uniformity} do describe assumptions made about the ``sameness'' of various properties of flows. The constant bit-rate (\caps{CBR}) model, for example, is an assumption about the uniformity of all of a flow's packets: i.e. that they have the same size and are evenly spaced in time. While this is the strictest sense of the \caps{CBR} model, it is rare for this assumption to be made in isolation. Another common simplification is to make the sizes of flows identical, or chose them randomly from a uniform distribution; similarly for the starting time of each flow. Finally, when choosing endpoints for a given flow, lacking a better model, it is not unusual to treat all nodes identically, making each an equally likely source or destination for a given flow.

%It is common in generating traffic behaviors for experiments to treat packets, nodes, and flows uniformly to varying degrees. This is largely because of the high complexity of doing otherwise and the lack of compelling alternatives. Here we examine how various notions of uniformity are expressed in the matrix model. In general, \textit{intra-flow uniformity} is effected by right multiplication, which mixes the elements in each row, whereas \textit{inter-flow uniformity} is effected by left multiplication, which mixes elements across rows. The constant bit-rate (\caps{CBR}) flow model, for example, in its strictest sense, is an intra-flow model, which stipulates that all the packets in each flow behave identically, having identical sizes and intervals; thus each flow's bit-rate is constant, as the name implies. The strict \caps{CBR} model can be easily expressed with the packets-bytes-duration (\caps{PBD}) model used as an example in \Section{representations}. The pair of matrices $\seq{\mat{Z},\mat{V}}$ is transformed to \caps{PBD} form using the vectors defined in \Section{flow-totals}: $\seq{\mat{Z},\mat{V}}\Gamma\in\R^{f \times 3}$, where
%\begin{align}
%\Gamma=\begin{pmatrix}
%\ones{} & \vec{\sigma} & \zeros{} \\
%\zeros{} & \zeros{} & \vec{\tau}
%\end{pmatrix} \in \R^{(d_v+d_z)\times{3}}.
%\end{align}

\subsection{Marginal Behavior}

Marginality is an orthogonal concept to uniformity: the distribution of some property is identical \textit{across} all flows. For example, if we determine a distribution of flow sizes across the entire network and assume that this distribution applies \textit{independent of other flow properties}, this is a marginal model for flow size. Marginal behavior is effected by left multiplication by a matrix with uniform columns. This specific example is generated by left-uniformizing the flow size matrix: $\mat{B}' = (\ones{f \times f}/f)\mat{B}$.
The traffic models proposed by {\FHC} are all marginal: they propose certain network-wide parametric distributions for start times, flow sizes and the number of flows per node. These models do not account for non-independence between these and other flow properties. We will discuss this limitation and its implications when we analyze our experimental results.

\subsection{Regularized Behavior}

The final form of homogenization we consider, is regularization. This is a restricted form of marginality: we may assume that marginal distributions apply to all the flows in certain groupings. For example, we can provide a distribution of flow sizes on a per-source basis. That is, each source node can have its \textit{own} distribution, and the sizes of its flows are drawn from that distribution, independent of their other properties. This is simply accomplished by left-multiplication by a non-uniform matrix. For example, to make flow behavior uniform on a per source basis, we left-multiply by the ``source-uniformizing'' matrix: $\mat{F}'=(\trans{\mat{SS}}/f)\mat{F}$. Per destination uniformity can be achieved similarly, with left-multiplication by a corresponding destination-uniformizing matrix: $F'=(\trans{\mat{DD}}/f)\mat{F}$.
%Although assumptions about uniformity across flows are common, there is little agreement about which notion of uniformity is most appropriate; often it is simply left unspecified. The confusion arises due to the lack of a unique way of associating flows with nodes. Each node can equally viably be associated with its source or its destination. Which association is more valid? Consider a web request: should the behavior of the request be determined by what the client typically does? Or should the requests that the server typically receives determine behavior? There is no armchair answer: only analysis of real data can give us the answer. The matrix model provides an analytical framework for doing so.
The matrix model has the benefit of making the uniformization of behaviors completely explicit. It also allows us to easily define intermediate choices. If we wish make the behavior of each flow a weighted average of the aggregate behaviors of its source and destination nodes, we can express this easily:
\begin{align}
\mat{F}' = \frac{1}{f}((1-\alpha)(\trans{\mat{SS}})+\alpha(\trans{\mat{DD}}))\mat{F}.
\end{align}
The parameter $\alpha$ allows us to smoothly vary the weighting of the source and destination behaviors. Source-only behavior is given by $\alpha=0$; destination-only by $\alpha=1$; to weight source and destination equally, take $\alpha=\frac{1}{2}$.

%We use the terms here to distinguish three fundamentally different types of assumptions about behavioral homogeneity.

%Existing traffic models are typically not explicit methods of generating complete synthetic traces of network traffic, but rather descriptions of some aspect of of the behavior of idealized traffic. In our algebraic modeling framework, such models can be interpreted as stipulations about the form of the behavior matrices, or as transforms that implement those stipulations given a real set of traffic matrices.

%A generic traffic model is a way of generating the six matrices described in \Section{representations}. A trace-derived traffic model transforms the matrices for an actual trace of network behavior into a simplified or regularized form. For experimental comparison, the dimensions of the matrices should all be preserved. If a trace-derived model produces experimental performance metrics that are similar to those produced by the original trace data, then simplifications made by the model are viable; if the performance is distorted, then the simplifications are discarding essential information about the traffic pattern.

%\subsection{Uniformity}

%% TODO: differentiate between restrictive versions of models and transformative versions.
%% TODO: distinguish uniform, marginal and regularized models.

%\subsection{Marginality}

%Most approaches to traffic modeling that go beyond uniformity assumptions, instead describe marginal properties of various aspects of traffic behavior. For example, {\FHC}~\cite{Hernandez06:wlan-traffic} provide highly convincing parametric models for six marginal properties of wireless network traffic: session (node) arrivals follow a time-varying Poisson process; per-session flow inter-arrival times are Lognormally distributed; flows per session (node) follow a BiPareto distribution; flow sizes follow a BiPareto distribution. This is certainly much greater detail than simply assuming that all nodes and flows are identical.

%How do marginal models translate into the algebraic language of the General Matrix Model? Whereas uniformity assumptions for nodes, 

%Another benefit of the matrix model is that all aspects of network behavior are determined concurrently. We are not left wondering what to do about source and destination nodes or flow start and end times after we have computed our simplified packet behaviors: the same transformation that average the packet behaviors also naturally averages the start and

\begin{table*}
\begin{center}
\small
\begin{tabular}{|c|c|l|}
\multicolumn{1}{c}{\textbf{model}} &
\multicolumn{1}{c}{\textbf{transformation}} &
\multicolumn{1}{c}{\textbf{description}} \\
\hline
\caps{GMM} & --- & the general matrix model \\\hline\hline
time uniform & $\mat{A}'=\mat{A}(\ones{d_t \times d_t}/d_t)$ & all start times are equally likely \\\hline
node uniform & $\mat{S}'=\mat{S}(\ones{n \times n}/n)$~~~~$\mat{D}'=\mat{D}(\ones{n \times n}/n)$ & nodes behave stochastically identically with respect to flows \\\hline
full uniform & \textit{all uniform transformations} & applies all the uniformity assumptions of the above models \\\hline\hline
time marginal & $\mat{A}'=(\ones{f \times f}/f)\mat{A}$ & start times chosen from marginal distribution of start times \\\hline
size marginal & $\mat{B}'=(\ones{f \times f}/f)\mat{B}$ & flow size (bytes) is chosen independently of other properties \\\hline
node marginal & $\mat{S}'=(\ones{f \times f}/f)\mat{S}$~~~~$\mat{D}'=(\ones{f \times f}/f)\mat{D}$ & nodes behave distinctly, but behavior is independent of flows \\\hline
packet marginal & $\mat{Z}'=(\ones{f \times f}/f)\mat{Z}$~~~~$\mat{V}'=(\ones{f \times f}/f)\mat{V}$ & packet behavior is variable bit-rate, aggregated across all flows \\\hline
full marginal & \textit{all marginal transformations} & applies all the marginality assumptions of the above four models \\\hline\hline
source regular & $\mat{F}'=(\trans{\mat{SS}}/f)\mat{F}$ & flow behaviors are aggregated on a per source-node basis \\\hline
dest regular & $\mat{F}'=(\trans{\mat{DD}}/f)\mat{F}$ & flow behaviors are aggregated on a per destination-node basis \\\hline
mixed regular & $\mat{F}'=\frac{1}{2f}(\trans{\mat{SS}}+\trans{\mat{DD}})\mat{F}$ & flow behaviors are aggregated on a mixed source/destination basis \\\hline
\end{tabular}
\caption{Matrix-based traffic models evaluated by paired differential simulation.}
\label{tab:traffic-models}
\end{center}
\vspace{-2em}
\end{table*}

\section{Experimental Methodology}
\label{sec:methodology}

To evaluate whether traffic models are realistic or not, we use the method of \textit{paired differential simulation} introduced in our previous work on traffic modeling~\cite{Karpinski07:realism,Karpinski07:cbr-failure}. %This approach is based on the following definition:
%
%\begin{samepage}
%\noindent\textbf{Definition.}~A model of user behavior is \textit{sufficiently realistic} if, compared with actual user behavior, the model, with parameter values extracted from the real data, yields statistically equivalent performance results.
%\end{samepage}
%\vspace{0.5em}
%
Paired differential simulation is based on the standard scientific technique of controlled experimentation. 
The hypothesis we are testing is that a given synthetic model accurately reproduces the performance metrics exhibited by real network traffic. To test this hypothesis, we conduct a series of paired experiments and compare the results for each test subject with a corresponding control subject. In this case, the experiments are wireless network simulations, and the subjects are real or synthetic workload instances. The control group is the set of simulations where the workload is an actual traffic trace, recorded as described in \Section{trace-data}. The test group is a set of simulations where workload is synthetically generated using a simplified traffic model. The experiments are paired: for each control simulation, there is a synthetic workload, with behavior as similar to the control as model will allow, against which the results are compared. The output of the series of experiments are paired values of performance metrics for each simulated scenario: one from the control, one from the test model.

The remainder of this section proceeds as follows. In \Section{traffic-models} we present the collection of traffic models we will evaluate. In \Section{trace-data} we describe the trace data that serves as the control for our experiments. Our simulation methodology is detailed in \Section{simulations}, and the performance metrics used for statistical comparison of control and test experiments are described in \Section{performance-metrics}. Finally, \Section{measures-of-error} is an in-depth mathematical discussion of the appropriate measure of error for the pairs of metric values that are produced by the paired differential simulation methodology.

% to compare traffic produced by synthetic models with known examples of recorded trace traffic in a variety of experimental scenarios. To accomplish this, we begin with a large 24-hour example of wireless trace traffic, break it into 144 ten-minute scenarios, and use each scenario's simulated trace behavior as a control for a set synthetic traces, generated by various traffic models. For each scenario, the synthetic models are configured to approximate the original trace behavior as closely as the models allow. Important network-wide performance metrics are then collected from simulations, and synthetic performance results compared with control results to determine the realism of the synthetic models.

%The art of simulation lies in knowing which details must be realistic and which may be abstracted into simpler, approximate models without affecting the accuracy of the results. Clearly, we need not simulate subatomic particle interactions in a wireless network simulator. Instead we use high-level physical models that approximate the real physics well enough that the performance results are the same. Similarly, when modeling network usage, we must require that our models produce the same results as actual user behavior. This requirement leads us to the following definition:

%This definition depends on many factors: the type of wireless scenario, the performance metrics under consideration, the actual usage behavior used for comparison, and how strong a notion of statistical equivalence is required. We discuss different measures of error and how to evaluate statistical equivalence in Sections~\ref{sec:error-measures}~and~\ref{sec:statistical-equivalence}.

\subsection{Traffic Models}
\label{sec:traffic-models}

The first model we evaluate is the General Matrix Model itself. We derive the matrix representation directly from the trace data and use it to generate workload as described in \Section{traffic-generation}. This serves to test whether the \caps{GMM} is sufficiently general: if it accurately reproduces all performance metrics across the collection of scenarios simulated, this provides strong evidence that \caps{GMM} captures enough of the detail of trace behavior to be considered a sufficiently general representation of network traffic patterns. %An affirmation of the generality of the \caps{GMM} acts as reduction of the 

After validating the \caps{GMM}, we explore the effects of various uniformity, marginality, and regularization assumptions on the realism of traffic models. The uniform models are the most common, being the simplest both to conceptualize and to implement: simply make no distinction between start times, source or destination nodes. Choose them at random, using no information from reality other than the number of nodes and the possible range of start times. We do not evaluate uniform packet behavior because it has been sufficiently discredited in our previous work.

In more sophisticated modeling work, where uniformity is discarded as too simple a model for behavior, marginality is often applied instead. It is assumed---often implicitly---that marginal models are adequate to capture the essential aspects of network behavior. We put that implicit assumption to the test here. How well do perfect marginal models represent real behavior? When we say that our marginal models are ``perfect,'' we mean that they are nonparametric and calculated directly from trace behavior. These are the marginal models that most accurately describe the trace traffic, because they are directly derived from it and make no parametric simplifications. This provides an upper bound on the quality of marginal models in general, since parametric marginal models are derived, in turn, as simplifications of these nonparametric marginal behaviors. \Table{traffic-models} provides a complete list of all the traffic models we compare in our evaluation.

%The original trace traffic serves as a control group against which to compare all other models. Before we can evaluate the General Matrix Model (\caps{GMM}), we must establish that one potentially important aspect of traffic behavior that is \textit{not} represented in the \caps{GMM} can legitimately be discarded. That aspect of behavior is \textit{\caps{TCP} feedback}. The \caps{GMM} does not specify the \caps{IP} protocol type of each flow. Therefore we must establish the extent to which using \caps{UDP} flows, without reliable delivery or congestion control, affects performance metrics.
%%\caps{GMM} also does not indicate which flows are paired with each other in a client-server relationship. While this pairing does not affect non-\caps{TCP} flows, we implement.
%Other synthetic models derived from algebraic transformations of the \caps{GMM} are listed in \Table{traffic-models}.

\subsection{Trace Data}\label{sec:trace-data}
%\subsection{Trace Data \& Simulations}\label{sec:trace-data}\label{sec:simulations}

Our general methodology is to compare performance metrics in simulations using real traffic patterns from traces to the same metrics in simulations using a variety of trace-based models and synthetic traffic models defined using the General Matrix Model. We use a 24-hour trace recorded in an infrastructured 802.11g wireless \caps{LAN} with 18 access points, deployed at the 60th Internet Engineering Task Force meeting (\caps{IETF}60), held in San Diego during August of 2004. The traffic trace was captured using \texttt{\small{tcpdump}} at a single router, through which all wireless traffic for the meeting was routed, including traffic between wireless nodes. The snap length of the capture was 100 bytes, allowing \caps{IP}, \caps{ICMP}, \caps{UDP} and \caps{TCP} headers to be analyzed. We limit our work to the 24-hour sub-trace recorded on Wednesday, August 4th. This trace contains a broad variety of behaviors and entails a very large volume of traffic: 2.1 million flows, 58 million packets, and 52 billion bytes.
% 2,085,563 flows, 58,377,994 packets of application data, and 51,988,245,537 bytes of application data.

\begin{figure}[t]
\vspace{0.5em}
\begin{center}
\includegraphics[width=3.3in]{nodes-flows}%
\vspace{-1.25em}%
\caption{The number of active nodes and flows over time.} 
\label{fig:nodes-flows}
\end{center}
\vspace{-2em}
\end{figure}

We do not assume or claim that the traffic found at \caps{IETF}60 is representative of conference settings in general. The observed behaviors are also unlikely to resemble those found in a typical commercial or residential setting. We have chosen this trace, however, because within it can be found behaviors resembling many different types of wireless usage cases. \Figure{nodes-flows} shows the wide variations in the number of active flows and nodes over the course of the trace. In the night and morning hours, the traffic patterns are similar to those one might find in a moderately trafficked business or residential area. During working group sessions, we see highly concentrated, heavy usage patterns. At the zenith of activity, over 800 users, 33 thousand flows, and 1 million packets are seen in a single 10-minute trace segment. At the nadir, a lone node sent only a single 61-byte packet over the course of 10 minutes. All levels of activity between these extremes are represented. Moreover, the mix of traffic types observed changes dramatically over the course of the day, providing a wide representation of possible blends of behavior. This heterogeneity and extreme range of behaviors makes the \caps{IETF} data set ideal for this evaluation. The variety of activity gives us greater confidence that success or failure of traffic models is not tied to any specific network condition, but is broadly and generally applicable. %For a traffic model to be truly realistic, it must be realistic across many different usage cases.

Before using the traces, it is necessary to extract application-level behavior from the trace header data. First, we split the trace into individual packet flows. A flow is a series of packets sharing the following five attributes: \caps{IP} and transport protocols (raw \caps{IP}, \caps{ICMP}, \caps{TCP}, \caps{UDP}); source and destination \caps{IP} addresses and \caps{TCP}/\caps{UDP} port numbers. Next, the quantity of application-initiated data contained in each packet is calculated. For non-\caps{TCP} packets, this quantity is simply the size of the transport-layer payload, but for \caps{TCP} the calculation is more complicated: only new data transfers, explicitly initiated by the application are counted. Data retransmitted by \caps{TCP} is disregarded, and empty \caps{ACK}s are ignored. \caps{SYN} and \caps{FIN} flags in packets (even empty ones) are counted as a single byte each, since they are explicitly signaled by the application. %After processing, we have a collection of flows, each with a sequence of timestamps and the amount of application-initiated data sent at that time.

\subsection{Simulations}
\label{sec:simulations}

We use the Qualnet wireless network simulator (version 4.0.1) to perform our experiments. We simulate a stationary multi-hop 802.11g network using the Ad hoc On-demand Distance Vector (\caps{AODV}) routing protocol~\cite{rfc:aodv}, with nodes placed randomly in a square field with sides of 150 meters.
In addition to the active nodes corresponding to trace \caps{IP}s, half as many passive ``infrastructure'' nodes are added to each simulation: these nodes initiate no data and simply serve as additional network relays. Our simulations resemble multi-hop mesh networks of the kind that are increasingly studied and deployed for delivery of broadband access in residential, corporate and conference settings. We do not attempt to reproduce the physical environment of the original wireless network, nor do we simulate mobility. The only aspect of the original network's behavior that is reproduced is the total pattern of network-wide traffic.

There are a number of potential objections to this approach. We use single-hop trace data to drive multi-hop simulations; the physical environment, node mobility, handover behavior, and closed-loop dynamics of the original wireless setting are not faithfully reproduced. One must keep in mind, however, that the goal of this research is \textit{not} to understand the conditions of the original network. Rather, we are using the traffic behaviors observed as examples to help us better understand how different types of workload can affect performance metrics. In particular, we aim to understand how real workload compares with common synthetic traffic models. Of course, the reason for such objections is that networking researchers understand that the many aspects of behavior interact with each other in a complex and nearly inextricable manner. However, before we can hope to understand the interaction between workload and other features affecting network behavior, we must study traffic patterns alone, and learn to model them with reasonable accuracy in the absence of additional complicating factors. Accordingly, in this study, we detach application level traffic patterns from the other factors influencing network conditions, and study them in isolation.

The 24-hour trace is split into 144 10-minute segments, each of which serves as the basis for a set of simulations using different traffic models. The traffic models range from a completely realistic trace-driven model, to a standard \caps{CBR} traffic model. Various partially synthetic intermediate models, described in \Section{traffic-models}, are simulated to study the impact of different aspects of traffic behavior on network performance. To preserve the fairness of the performance comparison, we keep as many features as possible constant across different traffic models. The traffic generated by each synthetic model preserves as many characteristics from the original trace as possible, within the constraints of the model. Moreover, the following features are preserved across all models: the number of wireless nodes, the number of flows, the number of application-initiated data units sent, the total bytes of application data sent, and the average flow duration (and therefore the average data rate).

In our previous work, we approximated \caps{TCP} with a pair of half-duplex \caps{UDP} flows~\cite{Karpinski07:realism,Karpinski07:cbr-failure}. For this work, we have implemented a new Qualnet application driver that allows trace-driven full-duplex \caps{TCP} flows. This allows us to accurately reproduce the full dynamics of \caps{TCP} feedback. Moreover, raw \caps{IP}, \caps{UDP} and \caps{TCP} flows are implemented using the same code, guaranteeing that all traffic is simulated uniformly and that all performance metrics are aggregated in the same manner. We have also instrumented Qualnet to collect \caps{IP} performance metrics in strict adherence to the recommendations of the \caps{IETF} working group on \caps{IP} performance metrics~\cite{rfc:ip-metrics}.

\subsection{Performance Metrics}
\label{sec:performance-metrics}

We have selected six performance metrics to present here. They are commonly used as indicators of network performance at the application, network, and link layers of the protocol stack:
\begin{enumerate}
\setlength{\itemsep}{0em}
\item \textbf{Application:} average end-to-end delay, packet delivery ratio, received throughput.
\item \textbf{Network:} \caps{AODV} control overhead (\caps{RREQ/RREP/\\RERR}), packets dropped in routing queues.
\item \textbf{Link:} 802.11 control overhead (\caps{RTS/CTS/ACK}).
\end{enumerate}
These metrics are commonly used to evaluate wireless protocols. We have examined a broad variety of other wireless network performance metrics, and although we do not have room to present or discuss them here, the results shown are representative of the overall realism of the traffic models.
%For each of the 144 10-minute trace segments, we have run simulations using each of the nine traffic models, for a total of 1,296 simulations.
%Unfortunately, not all of the simulations were able to run to completion. In some scenarios, the number of nodes and flows caused Qualnet to simply fail. We were, however, able to get complete results for 72.5\% of the simulations, providing a clear view of overall trends.\!\footnote{That 27.5\% of simulations did not finish may seem like a cause for concern, but it does not in fact invalidate our results. The simulations that did not finish are those for which the number of flows and nodes overwhelmed the capacity of the simulator. Qualnet cannot simulate more than circa 650 nodes sending 35,000 flows. While it would be of great interest to examine results for these large-scale scenarios, they are essentially useless for comparison to other simulations studies: other studies do not simulate this quantity of nodes and flows precisely because even the best existing simulators do not support it. Once the simulators become more scalable and robust, our analysis can be extended to these scenarios as well.}

\subsection{Measures of Error}
\label{sec:measures-of-error}

The simulations described in \Section{simulations} provide us with the raw data to compare performance metrics for synthetic traffic models with those for real traffic traces. To assess the realism of these models, however, we need a measure of how inaccurate the synthetic performance values are when compared to the real values. Let $x$ be the value of a performance metric using real traffic, and $y$ the value of the same metric using an alternate traffic model. Some common measures of error are the difference [$y-x$], the ratio [$y/x$], and the relative error [$(y-x)/x$], also commonly called the ``standard error.'' These are all reasonable measures of error; but which is most appropriate for assessing the realism of performance metrics? Instead of picking one arbitrarily, we will first consider the properties that an ideal error function should have, and then use those properties to determine the best measure of error. Moreover, we will show that the unique measure of error that exhibits these ideal properties is the  \textit{log-ratio} of metric values:
\begin{align}
\log(y/x)=\log(y)-\log(x).
\end{align}
In this discussion, $E(x,y)$ is a generic error function applied to the synthetic value, $y$, with respect to the real value, $x$.

The first property that an error function should have is  \textit{insensitivity to common factors}. That is, if both values are scaled by the same constant, the error should be unaffected:
\begin{align}
\label{eqn:normalization-invariance}
\forall\: x,y,c: E(x c,y c) &= E(x,y)
\end{align}
There are three major motivations for this requirement:
\begin{enumerate}
\item Changing units should not affect error values.
\item Error values for ``large'' and ``small'' scenarios should be directly comparable. Scenarios with large $x$ values will naturally have larger raw differences between $x$ and $y$. This requirement allows scenarios of different scales to be compared fairly and without bias.
\item Changing between metrics that differ by a known constant for each scenario should not affect error values.
\end{enumerate}
The last point is best illustrated by an example. Consider two closely related performance metrics: average throughput, $t$, and total bytes received, $r$. Suppose that there are $f$ flows in a given scenario with average duration, $d$. Since $t =r/fd$, the metrics $t$ and $r$ contain the same information---they differ only by a known constant in each simulation scenario. Equation~\ref{eqn:normalization-invariance} ensures that the errors of these metrics are the same:
\begin{align}
E(t_{\text{trc}},t_{\text{mod}})
	= E\left({\frac{r_{\text{trc}}}{fd},\frac{r_{\text{mod}}}{fd}}\right)
	= E(r_{\text{trc}},r_{\text{mod}}).
\end{align}
The difference measure does not satisfy Equation~\ref{eqn:normalization-invariance}, but the ratio, relative error, and log-ratio error measures all do.

The second property that an ideal error function should have is  \textit{additivity of compounded errors}. If two independent causes of error each induce some factor of misrepresentation, then the combined error should be the sum of the errors caused by each factor separately:
\begin{align}
\label{eqn:linear-compounding}
\forall\: x,c_1,c_2:
	E(x,x c_1 c_2) &= E(x,x c_1) + E(x,x c_2).
\end{align}
This property allows us to compare error values meaningfully across different traffic models.
%For example, if flow topology and packet behavior affected some performance metric independently with no interaction effects, we would expect that
%\begin{align}
%E(x^\TTT,x^\UTU) \approx E(x^\TTT,x^\TTU) + E(x^\TTT,x^\UTT).
%\end{align}
%If these two values differ significantly, there must be some interaction between the two levels of behavior that introduces more error than can be explained by each separately. Without the property of additivity given in Equation~\ref{eqn:linear-compounding}, such a comparison would not be possible or meaningful.

Additivity of compounded errors also implies two desirable properties that are easily derived from Equation~\ref{eqn:linear-compounding}. It forces the error of an accurate representation to be zero: $E(x,x) = 0$. It also forces underestimation and overestimation to be treated symmetrically. The error of underestimating by some factor is opposite but equal to overestimating by the same factor:
\begin{align}
E(x,x/c) = - E(x,xc).
\end{align}

It is easily verified that the difference, ratio, and relative error measures do not satisfy \Equation{linear-compounding}, and the difference, as noted, does not satisfy \Equation{normalization-invariance}. The log-ratio is the only metric presented that satisfies both conditions. Moreover, it can be proved that $\log(y/x)$ is the \textit{only} differentiable function that satisfies both (up to a constant). In the Appendix, we present a proof of this claim. Throughout the rest of the paper, we use the log-ratio to measure the error of performance metrics.
% TODO: should Appendix be capitalized?
% TODO: hyperref the Appendix for PDF.

\section{Results}
\label{sec:results}

\begin{sidewaysfigure*}
\subfloat[\textbf{Application:} Average End-to-End Delay]%
{\includegraphics[width=4.45in]{plots/Application/delay.pdf}}\hfill
\subfloat[\textbf{Application:} Packet Delivery Ratio]%
{\includegraphics[width=4.45in]{plots/Application/delivery_ratio.pdf}}
%
\subfloat[\textbf{Application:} Average Received Throughput]%
{\includegraphics[width=4.45in]{plots/Application/throughput.pdf}}\hfill
\subfloat[\textbf{Network:} AODV Control Overhead]%
{\includegraphics[width=4.45in]{plots/Network/control_packets.pdf}}
%
\subfloat[\textbf{Network:} Packets Dropped in Routing Queue]%
{\includegraphics[width=4.45in]{plots/Network/dropped.pdf}}\hfill
\subfloat[\textbf{Link:} 802.11 Control Overhead]%
{\includegraphics[width=4.45in]{plots/Link/overhead.pdf}}%
%
\caption{%
Box-and-whisker plots of log-ratio error values for all metrics and traffic models. The lower axis indicates the log-ratio, while the upper axis shows raw ratio values. Each box contains the central majority of log-ratio values: the left and right bounds are at the $25^\text{th}$ and $75^\text{th}$ percentiles. The dark middle line indicates the median value, while the diamond marks the mean. The whiskers (dotted lines) extend to the furthest non-outlier values, while the points beyond that are outliers. The notch in the middle of each bar indicates a $95\%$ confidence interval for the true underlying median value; if two notches do not overlap, they are very unlikely to have the same median.
}
\label{fig:box-plots}
\end{sidewaysfigure*}

Our simulation results are summarized in \Figure{box-plots}. Each subfigure shows a single performance metric. The distribution of log-ratio error values for each traffic model is visualized with a box-and-whisker plot. The box indicates the range from the 25th to 75th percentiles of values, while the ``whiskers'' indicate the full range, excluding outliners (which are shown as isolated points). These plots allow immediate assessment of realism: a good traffic model should have error values that are tightly clustered around the center, with a small, evenly balanced box, and relatively small whiskers. Additionally, the mean and median markers should be close to the center. It should be noted that the error scale is logarithmic, so even a slight increase in spread or deviation from the center indicates a disproportionately large decrease in model quality. Non-logarithmic scale markers are shown above each plot; the values indicate the factor of over- or under-representation for the performance metric.

The primary result is that the \caps{GMM} accurately reflects the performance of the trace data it is based on. It has small, centered error bars for every performance metric presented here, as well as for those we have looked at otherwise. This is an essential result, since otherwise, \caps{GMM} is at best a shaky foundation for further modeling work. With these results, we can be assured that if we can approximate the matrix for a given example of trace traffic, then we have also approximated the original trace behavior. In a sense, this result is a reduction of the general traffic modeling problem to a more tractable matrix modeling problem.

It is worth noting that \caps{GMM} has competition from a few of the time-simplified models: the \model{time marginal} and \model{time uniform} model both do approximately as well, and in some cases better, for the metrics examined. {\FHC} found strong evidence that session arrivals followed a time-varying Poisson arrival process, meaning that other than long-scale time-varying arrival rate and very small-scale clustering of flows within sessions, the overall flow arrival rate is fairly smooth. We suspect that on the scale of minutes to tens of minutes in which our simulation exist, it is sufficient to model both flow and session arrivals uniformly. This result indicates that the precise temporal placement of flows is not highly sensitive: they tend to be relatively evenly spaced out at short time-scales, and network performance is not sensitive to changes in start-time on that scale.

Not all marginal models have such a benign effect on the accuracy of performance metrics. The worst offender by far is the \model{size marginal} model. This model distorts behavior at every level, by more than a factor 20 in 25\% of scenarios in the case of routing queue packet drops. This is a highly significant result because modeling flow size using a network-wide marginal distribution is precisely what {\FHC}, for example, attempt. This results informs us that this approach is doomed to failure: flow size cannot be assigned without considering its relation to other flow properties: source and destination nodes, and packet behavior at the very least.

The \model{packet marginal} model is another offender, albeit not as egregiously. The direction of the misrepresentations in this case, however, is more dangerous: received throughput is overestimated by more than three times, 75\% of the time. On the other hand, \caps{AODV} control overhead is underestimated by half on average. Such serious misrepresentations are especially noteworthy given the apparently innocuous assumption applied by this model: the \model{packet marginal} model is essentially a standard variable bit-rate (\caps{VBR}) packet behavior model, using the empirical network-wide distributions of packet sizes and inter-packet intervals. Otherwise the model matches the original trace behavior exactly. And yet these drastic distortions occur. In our previous work, we have shown similarly drastic misrepresentations to occur when constant bit-rate packet behavior is assumed. This results indicates that to reproduce accurate network performance, we must provide packet behaviors on a more granular level: each node or even each flow must be assigned a ``custom'' packet behavior by some means.

These strong negative results for two fundamental and very common marginal models provide severe limits on the realism that can be achieved through marginal modeling. Traffic modeling research \textit{must} move beyond simply finding parametric models for marginal distributions of network-wide properties. Realistic behavior cannot be generated using these distributions alone. Something must be captured about the interaction between the elements of flow behavior.

Finally, we turn to the regularized models. These demonstrate neither exceptionally good nor exceptionally bad behavior. That the regularized models should be similar to the \model{full marginal} model but somewhat more realistic is entirely expected: regularization, the reader will recall, is a restricted form of marginal modeling, where each group of flows has its own marginal distribution. In these cases, the flows are grouped by source node or by destination node. The mixed case uses the average behavior of the other two cases. It is interesting to note that the mixed case is universally worse than either the source or destination case. Clearly, hybridizing the regularization here is not an effective technique. We believe that the cause of this effect is like mixing too many colors yielding an unpleasant shade of brown: any of the colors individually would be better than the non-descript average. As a more general conclusion, arbitrarily mixing model may not always be a good idea, despite the ease with which it is done in the matrix representation of workload behavior.

%We also believe that the fact that both the \model{time marginal} and \model{time uniform} models perform about as well as the \caps{GMM} indicates not that they are performing exceptionally well, but that the \caps{GMM} is performing worse than it should in this case. This may be an artifact of the interaction between packet behavior, flow size, flow duration and start time, as described in \Section{traffic-generation}. This remark may appear to be a non-sequitur, but these properties are all closely related. Consider that packet behavior (i.e. distribution of packet sizes and inter-packet intervals) determines the expected mean packet size and expected mean interval duration. The expected duration is then related to the flow size via the following equation:
%\begin{align*}
%\E{\text{duration}} = [\text{flow size}]\frac{\E{\text{mean interval}}}{\E{\text{mean size}}}
%\end{align*}
%The duration must also satisfy $t_{\text{start}}+[\text{duration}] \le t_{\max}$.

%It accurately reproduces important performance metrics at all levels of the protocol stack in simulation. This only moves us a step closer to being able to generate realistic, completely synthetic workloads, since the \caps{GMM} in these comparisons  derives almost all of its behavior directly from the trace. However, it means that we have effectively reduced the problem of generating realistic workload to the problem of classifying and understanding what sorts of traffic matrices occur in real workloads. Moreover, we can express a vast array of different approaches to traffic modeling simply and uniformly using matrix operations.

\section{Discussion}\label{sec:discussion}

%The story of network analysis and modeling is one of variety. Assumptions of ``sameness'' have fallen repeatedly. ...
%The matrix model gives new insight into 

What are the ramifications of these results? In our previous work, we had already demonstrated the drastic distortions that are introduced by uniformity assumptions made by the most common traffic models. This work serves to further critique established common assumptions in traffic modeling. The strongest message to be taken away is that the aspects of traffic behavior of both nodes and flows \textit{must} be considered jointly. It is not sufficient to continue modeling marginal distributions of network properties. These marginal models do not lend them selves easily to traffic generation in the first place, and when marginality assumptions are applied to trace traffic, the result is a severe distortion of important network performance characteristics. It is now well established that network traffic patterns have an impact on network performance that cannot be ignored. Even experimental deployments cannot avoid the need for more realistic traffic workload models. While using a real, physical network successfully sidesteps simulation problems below the application layer, without realistic traffic models, reliable, meaningful performance predictions remain beyond our reach.

%\subsection{Generality of Results}

%% TODO: talk about other synthetic models not considered here.
%% The point of our analysis is not to show that no synthetic models can be accurate, but rather, that the commonly used models, and obvious variations thereof, are not accurate.

%The most significant limitation on the generality of this analysis is that it is based entirely on a single data set from \caps{IETF}60---albeit a large and varied one. It is possible that traffic in this trace happens to produce network performance that is unusually dissimilar to standard traffic models. This data set, however, represents a highly heterogeneous collection of network usage behaviors, from slow and steady off-peak usage, to extremely heavy peak usage: over 800 users, 33 thousand flows, and 1 million packets in a single 10-minute trace segment. Despite the broad variety of behaviors, the results are consistent: in all types of usage scenarios, simplistic traffic models, like uniform \caps{CBR}, systematically skew important performance measurements at all levels of the network. While the precise results for other data sets might differ, it is very unlikely that \caps{CBR} traffic models will happen to accurately reproduce realistic performance in other experiments. This paper provides strong evidence that better traffic models are needed for performance evaluations.

\subsection{Towards Realistic Models of Wireless Workload}

What would better traffic models look like? How can we create them? One possible approach is to use actual traffic traces as we have done. This approach is unsatisfactory, however, because it provides the experimenter with almost no control over experiments. Synthetic models have parameters, which can be tweaked as necessary---adjusting, for example, the number of active nodes in a simulation, without affecting other parameters. Traffic traces, on the other hand, must be used without significant alteration if they are to actually provide the desired realism. This inability to control all but one or two parameters is nearly crippling for experimental purposes. Therefore, the research community needs models whose parameters can be adjusted independently, but whose performance characteristics can be made to resemble whatever example of network behavior one might need. The General Matrix Model does not yet fulfill this role since its parameters cannot be freely varied. We believe, however, that \caps{GMM} plays a vital role in the ongoing process of developing  of better models. By reducing the general problem of traffic modeling to the domain of linear algebra, we have provided traffic researchers with a vast array of powerful theoretical and computational tools that can be immediately applied to the problem at hand.\footnote{The derived models used in this paper were all implemented in Matlab, each in only a few simple lines. All the models used here are implemented in only 19 total lines of code. Of course, the framework to apply them to traffic traces and simulations is somewhat larger.} What are the next steps? The authors are currently investigating a variety of matrix factorization and clustering techniques to extract hidden structure from a large and diverse body of real traffic.

%The reader will note that the transformations applied in this paper are all quite simple. Our regularization matrices primarily consisted of ones and zeros. The algebraic representation of complete workload 

%The ``messiness'' of the performance comparison from trace data in Figure~\ref{fig:mac-control-overhead-cmp} illustrates why using traces directly is not ideal: each data point differs not only in the number of nodes shown on the $x$-axis, but also in other dimensions, such as the number of flows and packets, and the average flow duration. The result is a highly noisy comparison, affected by many unseen parameters. Only by applying a local smoothing algorithm are trends somewhat elucidated.

%Instead of using trace data directly, it should be possible to configure a synthetic traffic model based on observations from a real data set, and then run side-by-side simulations using the synthetic model and the real data, producing statistically equivalent performance results. This is precisely what our definition of sufficient realism entails. The work in this paper provides the tools to measure how close to this ideal a model is and in what areas it needs improvement. Without this feedback, any improvements in realism are purely guesswork. Our breakdown of traffic behavior into three orthogonal levels also allows the problem to be approached in smaller pieces, rather than being solved all at once.

%The next step towards better traffic models is to investigate which aspects of real traces may be altered without detrimentally affecting the resulting performance metrics. For example, to test whether a complex time-series model of packet behavior is necessary, we randomize the order of the packet sizes and/or inter-packet intervals and compare performance using these randomized traces against performance using the original traces. If the performance is unchanged, we can conclude that no complex time-series model of packet behavior is necessary: sampling the packet sizes and inter-packet intervals from empirical distributions is sufficiently realistic. If, on the other hand, the performance characteristics are altered by shuffling packets, then some time-series model of packet behavior is needed. By partially randomizing the packet order in specific ways, the exact limits of realism necessary can be found. A similar approach will allow the development of realistic models for the other levels of network usage behavior.

\section{Conclusions}\label{sec:conclusions}

%The real significance of this paper lies not in showing that the commonly used \caps{CBR} traffic model is unrealistic. Networking researchers understand that \caps{CBR} is at best a na\"ive approximation of real network traffic. Nor is the real significance that we have quantized the high degree of inaccuracy that can be induced by using this model. The real significance of this paper lies in providing an well-defined, objective measure of realism for traffic models. This has never previously existed: evaluations of realism have relied on essentially arbitrary statistical measures of similarity to real traffic. Existing traffic generators use empirical distributions of such quantities as file size, inter-connection time, packet size, or inter-packet intervals. They can only hope that reproducing these distributions as good enough. Without an external measure of accuracy, there's simply no way to know.

%attempting to showing that existing models are unrealistic, or that new models are more realistic have always focused on arbitrary statistical measures. A 

We have presented a fundamentally new, algebraic way of representing traffic patterns in local area networks. We call this representation the General Matrix Model. Each flow of a traffic collection is represented as a single high-dimensional vector with components representing the \caps{IP} protocol type, source and destination nodes, start time, flow size, and packet behavior. The essential property of the algebraic representation is that standard vector operations compute natural and useful descriptions of aggregate behavior over the collection of flows represented. Our experimental validation demonstrates clearly that the General Matrix Model accurately reproduces the performance characteristics of of real traffic. The benefits of a performance-preserving algebraic representation are multifold. The algebraic forms of the simplifying assumptions made by many common modeling approaches provide unprecedented clarity and coherence to a complex and confusing subject. For example, assumptions that various aspects of flow behavior are stochastically or deterministically uniform all take the same form algebraically: left matrix multiplication. The other major class of common simplifying assumptions made by traffic models is to apply some marginal behavior across the entire collection of flows or to disjoint subsets of the flows. Such simplifications correspond to right matrix multiplication in \caps{GMM}. Because of the simplicity and clarity that the algebraic structure brings to the subject, we can see clearly now that both common types of simplifying assumptions are na\"ive and simplistic. Our experimental results bolster this conclusion: both uniform and marginal models significantly misrepresent many important network performance metrics. With the General Matrix Model, however, we stand poised to use the powerful tools of modern linear algebra to develop general, elegant and powerful models of network behavior that just work.

%This research rigorously quantifies the impact of a variety of synthetic traffic models on performance metrics that wireless researchers use to evaluate new technologies and protocols. The first step in this assessment process was to formally define what it means for a network usage model to be sufficiently realistic. In essence, a model is considered realistic if it produces performance results that are statistically equivalent to those produced by real usage.
%A well-defined, objective measure of realism for traffic models has not previously existed. Evaluations of realism have formerly relied on essentially arbitrary statistical measures of similarity to real traffic, which may or may not affect the performance metrics that researchers care about.
%The definition of sufficient realism leads us to our general experimental approach: we use differential analysis comparing performance metrics derived from real traffic with those derived from synthetic traffic models. The theoretical contributions of this analysis are:
%\begin{enumerate}
%\item An in-depth analysis of the desirable mathematical properties of a measure of error for performance metrics.
%\item Proof that the unique measure of error that satisfies these properties is the log-ratio of metric values.
%\item Three rigorous tests of statistical equivalence between synthetic and real performance results.
%\end{enumerate}
%These analytical tools allow the evaluation of realism over a collection of drastically different usage scenarios. Evaluation over a heterogeneous collection of scenarios is essential to establishing the credibility of usage models. Moreover, these theoretical results are equally applicable to other types of usage models---for example, mobility.

%On the practical side, this paper gives crucial insight into why most researchers do not trust simulation results: with the traffic models commonly used, the results are unlikely to reflect real performance. Moreover, this problem will also hamper experiments in test-bed wireless networks, so long as the same na\"ive workload models are used. The only way to address this fundamental lack of realism is to develop usage models that reproduce important performance metrics more accurately. Our theoretical results provide the tools necessary to do this. The development of better traffic models should begin with real traces, and proceed by incremental changes, checked by differential analysis.
%%First, alter a small aspect of the trace, simulate, then compare. If the realism of the results is unaffected, the traffic feature altered was inessential. Otherwise, it is a feature of behavior that must be captured in a realistic traffic model.
%This approach will allow the precise mapping of which aspects of traffic patterns have an impact on performance and which ones can be safely abstracted away.
%% TODO: maybe cut out some of this last bit.

%\section{Acknowledgments}
%This work was funded in part through NSF Career Award CNS-0347886.

\section*{Appendix}
\footnotesize

\noindent
\textbf{Theorem.} The unique differentiable function satisfying Eqs.~\ref{eqn:normalization-invariance} and \ref{eqn:linear-compounding} is $E(1,e) \ln(y/x)$. \textit{Proof:} Let $f(z) = E(1,z)$. Eq.~\ref{eqn:normalization-invariance} gives $E(x,y) = E(1,y/x) = f(y/x)$. Eq.~\ref{eqn:linear-compounding} gives: $f(z) = f(z/w) + f(w)$. Differentiation by $z$ yields $f'(z) = w^{-1} f'(z/w)$. In particular, if we choose $w=z$, we get $f'(z) = z^{-1} f'(1)$. Integration by $z$ gives:
$f(z) = f'(1) \int z^{-1} dz + c = f'(1) \ln(z) + c$.
By Eq.~\ref{eqn:linear-compounding}, $f(1)=0$, so $c=0$. Thus $f(e)=f'(1)\ln(e)=f'(1)$. We conclude that $f(z)=f(e)\ln(z)$, so $E(x,y) = f(y/x) = f(e)\ln(y/x) = E(1,e)\ln(y/x)$, as desired.\hfill%\QED

%\vspace{1em}\noindent
%\textbf{Theorem.}~[\textit{Lyapunov's Central Limit Theorem}] Let $\{R_k\}_{k=1}^{\infty}$ be a series of independent variables with $\E{R_k}=0$. Let $s_n^2 = \sum_{k=1}^n{\E{\abs{R_k^2}}}$ and $r_n^3 = \sum_{k=1}^n{\E{\abs{R_k^3}}}$. For each $n$, let $Z_n$ be the normalized mean of $\{R_k\}_{k=1}^n$: $Z_n = \sum_{k=1}^n{R_k/s_n}$. If $\lim_{n\to\infty} {r_n/s_n} = 0$, then $\lim_{n\to\infty}{Z_n} \sim \mathcal{N}(0,1)$ (the standard normal distribution). (See~\cite{Feller68} page 229.)

%\vspace{1em}
%To apply the LCLT to the series $R_k^\M=\log(X_k^\M/X_k^\TTT)$, we must show that under the null hypothesis, the assumptions of the theorem are satisfied by this series. First, the null hypothesis, implies that $\E{R_k}=0$. Variables from separate simulations are independent since they cannot influence each other's values. Formally, $\Pr\left(X_k\middle|X_j\right)=\Pr\left(X_k\right)$. Therefore the log-ratios are also independent for different $k$. The last requirement is that $\lim_{n\to\infty}{r_n/s_n}=0$. To verify this, we use the estimators $\hat{s}_n^2=\sum{\abs{R_k^2}}$, and $\hat{r}_n^3=\sum{\abs{R_k^3}}$. When $\hat{r}_n/\hat{s}_n$ are plotted on a log-log scatter plot, with $n$ increasing up to the number of simulations, they asymptotically approach a downwardly sloped line as $n$ grows. Thus $\lim_{n\to\infty}{\ln(\hat{r}_n/\hat{s}_n)/\ln(n)}=c<0$. This implies that $\lim_{n\to\infty}{\ln(\hat{r}_n/\hat{s}_n)}=-\infty$, and therefore $\lim_{n\to\infty}{r_n/s_n}=\lim_{n\to\infty}{\hat{r}_n/\hat{s}_n}=0$. This test for the convergence of $r_n/s_n$ is applied to each model and metric pair. %The asymptotic approach of the ratio $\hat{r}_n/\hat{s}_n$ to a downwardly sloped line is verified visually and by comparison to a fitted regression line.

%\vfill

%\pagebreak
% Hernandez06:dissertation: ``complete methodology for reproducing the traffic observed on a network link in a closed-loop manner, and proposed a number of metrics for studying the realism of the generated traffic.''
\bibliographystyle{plain}
\bibliography{references}

\end{document}

